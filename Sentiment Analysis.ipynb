{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e8ea1e",
   "metadata": {},
   "source": [
    "## Exploratory Data analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143cecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19603f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "df= pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\smile-annotations-final.csv\", names=[\"id\",\"text\",\"category\"])\n",
    "df.set_index(\"id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e841e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing tweets having multiple emotions\n",
    "df = df[~df.category.str.contains(\"\\|\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05198be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df.category!=\"nocode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ea6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b7043",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df.category.unique()\n",
    "label_dict={}\n",
    "for index,possible_labels in enumerate(possible_labels):\n",
    "    label_dict[possible_labels]=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cadaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column label having numerical category\n",
    "df[\"label\"] = df.category.replace(label_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c59cd7",
   "metadata": {},
   "source": [
    "## Training/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee19b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val = train_test_split(df.index.values,df.label.values,test_size=0.15,random_state =17,\n",
    "                                               stratify = df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe900e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"data_type\"] = [\"not_set\"]*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[X_train,\"data_type\"] = \"train\"\n",
    "df.loc[X_val,\"data_type\"] = \"val\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"category\",\"label\",\"data_type\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c12cb8",
   "metadata": {},
   "source": [
    "## Loading Tokenizer and Encoding our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",\n",
    "                                         do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9498bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train= tokenizer.batch_encode_plus(df[df.data_type==\"train\"].text.values,\n",
    "                                              add_special_tokens = True,\n",
    "                                              return_attention_mask=True,\n",
    "                                              pad_to_max_length = True,\n",
    "                                              max_length = 256,\n",
    "                                              return_tensors=\"pt\")\n",
    "encoded_data_val= tokenizer.batch_encode_plus(df[df.data_type==\"val\"].text.values,\n",
    "                                              add_special_tokens = True,\n",
    "                                              return_attention_mask=True,\n",
    "                                              pad_to_max_length = True,\n",
    "                                              max_length = 256,\n",
    "                                            return_tensors=\"pt\")\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train=encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type==\"train\"].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val=encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type==\"val\"].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087bc4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train,attention_masks_train,labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val,attention_masks_val,labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d4fa2",
   "metadata": {},
   "source": [
    "## Setting up BERT Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5768ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78244d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels= len(label_dict),\n",
    "                                                     output_attentions=False,output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba27c9c",
   "metadata": {},
   "source": [
    "## Creating Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b28d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch =4 #32\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler = RandomSampler(dataset_train),\n",
    "                              batch_size= batch)\n",
    "dataloader_val = DataLoader(dataset_val,\n",
    "                              sampler = RandomSampler(dataset_val),\n",
    "                              batch_size= 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72db0745",
   "metadata": {},
   "source": [
    "## Setting up Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW( model.parameters(),\n",
    "                 lr =1e-5,\n",
    "                 eps =1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =10\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                           num_warmup_steps=0,\n",
    "                                           num_training_steps=len(dataloader_train)*epochs\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4dab24",
   "metadata": {},
   "source": [
    "## Definig our Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds,labels):\n",
    "    preds_flat= np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat,preds_flat,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds,labels):\n",
    "    label_dict_inverse ={v:k for k,v in label_dict.items()}\n",
    "    preds_flat= np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class:{label_dict_inverse[label]}')\n",
    "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e673a0",
   "metadata": {},
   "source": [
    "## Creating our Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed_val =17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals=[],[]\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs={'input_ids': batch[0],\n",
    "               'attention_mask':batch[1],\n",
    "               'labels':batch[2]}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        loss=outputs[0]\n",
    "        logits=outputs[1]\n",
    "        loss_val_total+=loss.item()\n",
    "        \n",
    "        logits=logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1,epochs+1)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train,\n",
    "                        desc='Epoch{:1d}'.format(epoch),\n",
    "                        leave= False,\n",
    "                        disable=False)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs={'input_ids': batch[0],\n",
    "               'attention_mask':batch[1],\n",
    "               'labels':batch[2]}\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total+=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.set_postfix({'training_loss':'{:.3f}'.format(loss.item()/len(batch))})\n",
    "        \n",
    "    torch.save(model.state_dict(), f'Models/BERT_ft_epoch{epoch}.model')\n",
    "    tqdm.write('\\nEpoch{epoch}')\n",
    "    loss_train_avg = loss_train_total/len(dataloader)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "        \n",
    "    val_loss, predictions,true_vals = evaluate(dataloader_val)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss:{val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted):{val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301fd05",
   "metadata": {},
   "source": [
    "## Loading and Evaluationg our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b32b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels= len(label_dict),\n",
    "                                                     output_attentions=False,output_hidden_states=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6baab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b58088",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043f9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
